{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNn7X5I7fvISVOS8lTD8Q5O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ullas33/Machine_Learning/blob/main/basic_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heG10JmVu6TC",
        "outputId": "5a71aa39-27b7-492a-d97f-19fb1d770e2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/172.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m121.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m299.4/299.4 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m129.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "psmisc is already the newest version (23.4-2build3).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "üì• Fetching action_theme.mp3...\n",
            "üì• Fetching calm_theme.mp3...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install -q streamlit opencv-python-headless onnxruntime-gpu gTTS moviepy cloudflared textblob kornia basicsr realesrgan\n",
        "!apt-get install -y ffmpeg psmisc\n",
        "\n",
        "import os, requests, subprocess, time\n",
        "import torch, numpy as np\n",
        "import cv2\n",
        "\n",
        "# Download Advanced Engines\n",
        "def get_model(name, url):\n",
        "    if not os.path.exists(name):\n",
        "        print(f\"üì• Fetching {name}...\")\n",
        "        r = requests.get(url)\n",
        "        with open(name, \"wb\") as f: f.write(r.content)\n",
        "\n",
        "get_model(\"AnimeGANv3_Hayao_36.onnx\", \"https://github.com/TachibanaYoshino/AnimeGANv3/raw/master/deploy/AnimeGANv3_Hayao_36.onnx\")\n",
        "get_model(\"action_theme.mp3\", \"https://www.soundhelix.com/examples/mp3/SoundHelix-Song-8.mp3\")\n",
        "get_model(\"calm_theme.mp3\", \"https://www.soundhelix.com/examples/mp3/SoundHelix-Song-2.mp3\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile anime_saas_4k.py\n",
        "import streamlit as st\n",
        "import cv2\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "import subprocess\n",
        "import os\n",
        "import torch\n",
        "from gtts import gTTS\n",
        "from textblob import TextBlob\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip, CompositeAudioClip\n",
        "\n",
        "# --- AGENT CORE: THE AETHER ENGINE ---\n",
        "class AetherEngine:\n",
        "    def __init__(self):\n",
        "        # Optimization: Use CUDA FP16 for 2x speedup on T4\n",
        "        opts = ort.SessionOptions()\n",
        "        self.session = ort.InferenceSession(\"AnimeGANv3_Hayao_36.onnx\",\n",
        "                                            providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
        "        self.prev_frame = None # For Temporal Smoothing\n",
        "\n",
        "    def temporal_smooth(self, current_frame, alpha=0.7):\n",
        "        \"\"\"Reduces flickering by blending with the previous frame's style.\"\"\"\n",
        "        if self.prev_frame is None:\n",
        "            self.prev_frame = current_frame\n",
        "            return current_frame\n",
        "        smoothed = cv2.addWeighted(current_frame, alpha, self.prev_frame, 1-alpha, 0)\n",
        "        self.prev_frame = smoothed\n",
        "        return smoothed\n",
        "\n",
        "    def transform_4k(self, frame, intensity, upscale):\n",
        "        h, w = frame.shape[:2]\n",
        "        # Neural Processing\n",
        "        blob = cv2.resize(frame, (512, 512)).astype(np.float32) / 127.5 - 1.0\n",
        "        out = self.session.run(None, {self.session.get_inputs()[0].name: np.expand_dims(blob, axis=0)})[0][0]\n",
        "        out = ((out + 1.0) * 127.5).clip(0, 255).astype(np.uint8)\n",
        "\n",
        "        # Upscaling & Blending\n",
        "        target_res = (3840, 2160) if upscale else (w, h)\n",
        "        anime_f = cv2.resize(out, target_res, interpolation=cv2.INTER_CUBIC)\n",
        "        anime_f = self.temporal_smooth(anime_f) # Temporal Coherence Step\n",
        "\n",
        "        orig_res = cv2.resize(frame, target_res)\n",
        "        return cv2.addWeighted(orig_res, 1 - intensity, anime_f, intensity, 0)\n",
        "\n",
        "    def produce_video(self, in_p, out_p, intensity, script, upscale):\n",
        "        cap = cv2.VideoCapture(in_p)\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        tw, th = (3840, 2160) if upscale else (int(cap.get(3)), int(cap.get(4)))\n",
        "\n",
        "        # PRO-GRADE FFMPEG PIPE (H.264 High Profile)\n",
        "        cmd = ['ffmpeg', '-y', '-f', 'rawvideo', '-vcodec', 'rawvideo', '-s', f'{tw}x{th}',\n",
        "               '-pix_fmt', 'bgr24', '-r', str(fps), '-i', '-', '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '18', '-pix_fmt', 'yuv420p', 'v_temp.mp4']\n",
        "        proc = subprocess.Popen(cmd, stdin=subprocess.PIPE)\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret: break\n",
        "            processed = self.transform_4k(frame, intensity, upscale)\n",
        "            proc.stdin.write(processed.tobytes())\n",
        "        proc.stdin.close(); proc.wait(); cap.release()\n",
        "\n",
        "        # INTELLIGENT AUDIO MAPPING\n",
        "        v_clip = VideoFileClip('v_temp.mp4')\n",
        "        audio_stack = [v_clip.audio.volumex(0.1) if v_clip.audio else None]\n",
        "\n",
        "        if script.strip():\n",
        "            gTTS(text=script, lang='en').save(\"voice.mp3\")\n",
        "            audio_stack.append(AudioFileClip(\"voice.mp3\"))\n",
        "            # Sentiment Analysis for Music Choice\n",
        "            score = TextBlob(script).sentiment.polarity\n",
        "            music = \"calm_theme.mp3\" if score > 0 else \"action_theme.mp3\"\n",
        "            audio_stack.append(AudioFileClip(music).volumex(0.2).set_duration(v_clip.duration))\n",
        "\n",
        "        final_audio = CompositeAudioClip([a for a in audio_stack if a is not None])\n",
        "        v_clip.set_audio(final_audio).write_videofile(out_p, codec='libx264')\n",
        "\n",
        "# --- AGENT UI: THE DIRECTOR'S CANVAS ---\n",
        "st.set_page_config(page_title=\"AetherAnime Agent\", layout=\"wide\")\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap');\n",
        "    .stApp { background: #0E1117; color: #E0E0E0; font-family: 'Inter'; }\n",
        "    .scene-box { border-radius: 20px; background: #161B22; border: 1px solid #30363D; padding: 25px; margin-bottom: 20px; }\n",
        "    .stButton>button { background: linear-gradient(90deg, #1A73E8, #0D47A1); color: white; border-radius: 8px; border: none; width: 100%; }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "if 'beats' not in st.session_state: st.session_state.beats = [{\"id\": 0, \"done\": False, \"file\": \"\"}]\n",
        "\n",
        "with st.sidebar:\n",
        "    st.title(\"üõ°Ô∏è Agent Status\")\n",
        "    st.success(\"Aether Engine: Online\")\n",
        "    upscale_4k = st.toggle(\"Unlock 4K Production\", value=True)\n",
        "    st.divider()\n",
        "    if st.button(\"üé¨ Final Master Export\"):\n",
        "        files = [b['file'] for b in st.session_state.beats if b['done']]\n",
        "        if len(files) > 1:\n",
        "            with open(\"f.txt\", \"w\") as f:\n",
        "                for fl in files: f.write(f\"file '{fl}'\\n\")\n",
        "            subprocess.run(['ffmpeg', '-y', '-f', 'concat', '-safe', '0', '-i', 'f.txt', '-c', 'copy', 'master.mp4'])\n",
        "            st.video(\"master.mp4\")\n",
        "            with open(\"master.mp4\", \"rb\") as f: st.download_button(\"Download Final 4K Movie\", f, \"anime_master.mp4\")\n",
        "\n",
        "st.title(\"‚õ©Ô∏è AetherAnime Agent\")\n",
        "st.caption(\"Advanced Video-to-Anime Production Suite ‚Ä¢ 2026 Edition\")\n",
        "\n",
        "for i, beat in enumerate(st.session_state.beats):\n",
        "    st.markdown(f\"<div class='scene-box'>\", unsafe_allow_html=True)\n",
        "    c1, c2 = st.columns([1, 1.2])\n",
        "    with c1:\n",
        "        st.write(f\"### Story Beat {i+1}\")\n",
        "        v_file = st.file_uploader(f\"Input Scene\", type=['mp4', 'mov'], key=f\"v{i}\")\n",
        "        script = st.text_area(\"Director's Script (AI Narrator)\", key=f\"t{i}\")\n",
        "        if v_in := v_file:\n",
        "            if st.button(f\"Generate Anime Beat {i+1}\", key=f\"b{i}\"):\n",
        "                with open(f\"tmp_{i}.mp4\", \"wb\") as f: f.write(v_in.getbuffer())\n",
        "                agent = AetherEngine()\n",
        "                out = f\"beat_{i}.mp4\"\n",
        "                with st.status(\"Agent is painting frames...\"):\n",
        "                    agent.produce_video(f\"tmp_{i}.mp4\", out, 0.85, script, upscale_4k)\n",
        "                st.session_state.beats[i]['done'] = True\n",
        "                st.session_state.beats[i]['file'] = out\n",
        "                st.rerun()\n",
        "    with c2:\n",
        "        if beat['done']: st.video(beat['file'])\n",
        "        else: st.info(\"Waiting for Director's Input...\")\n",
        "    st.markdown(\"</div>\", unsafe_allow_html=True)\n",
        "\n",
        "if st.button(\"‚ûï Add Story Beat\"):\n",
        "    st.session_state.beats.append({\"id\": len(st.session_state.beats), \"done\": False, \"file\": \"\"})\n",
        "    st.rerun()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfErT7ZAwE7z",
        "outputId": "be122e6d-1df7-4def-f660-0004c8b2d325"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting anime_saas_4k.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!fuser -k 8501/tcp\n",
        "subprocess.Popen([\"streamlit\", \"run\", \"anime_saas_4k.py\", \"--server.port\", \"8501\"])\n",
        "time.sleep(10)\n",
        "print(\"\\n\" + \"‚ïê\"*50)\n",
        "print(\"üõ°Ô∏è AETHER ANIME AGENT IS DEPLOYED\")\n",
        "print(\"1. Copy this IP:\", end=\" \")\n",
        "!curl -s ipv4.icanhazip.com\n",
        "print(\"2. Click this link and paste the IP to enter the Studio:\")\n",
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "hRI9UAyt91x1",
        "outputId": "2ea6cba7-5072-4873-8cf7-5b1ec59ff882",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "üõ°Ô∏è AETHER ANIME AGENT IS DEPLOYED\n",
            "1. Copy this IP: 136.118.3.212\n",
            "2. Click this link and paste the IP to enter the Studio:\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0Kyour url is: https://three-waves-thank.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}